---
title: "Analyze textual data for part II of basal attributes article"
author: "Julius Fenn"
format:
  html:
    toc: true
    toc-depth: 3
    html-math-method: katex
    number-sections: true
---


# global variables



```{r}
#| label: global variables


```


# Notes



# load data files


```{r}
#| label: load files
#| warning: false

# sets the directory of location of this script as the current directory
# setwd(dirname(rstudioapi::getSourceEditorContext()$path))

### load packages
require(pacman)
p_load('tidyverse', 'jsonlite', 'magrittr', 'xlsx',
       'stargazer', 'psych', 'jtools', 'DT', 'ggstatsplot', 
       'lavaan', 
       'regsem', 'MplusAutomation', 'igraph', 'ggplot2', 'tidyLPA', 'MultilayerExtraction',
       'Matrix', 'igraph', 'foreach', 'doParallel',
       'tm', 'topicmodels', 'RColorBrewer', 'wordcloud')


setwd("outputs/01_dataPreperation/final")
### load questionnaire
questionnaire <- readRDS(file = "questionnaire.rds")

CAMfiles <- readRDS(file = "CAMfiles.rds")

CAMdrawn <- readRDS(file = "CAMdrawn.rds")

CAMaggregated <- readRDS(file = "CAMaggregated.rds")

networkIndicators <- readRDS(file = "networkIndicators.rds")

CAMwordlist <- xlsx::read.xlsx2(file = "CAMwordlist.xlsx", sheetIndex = 1)
CAMwordlist$mean_valence <- as.numeric(CAMwordlist$mean_valence)
CAMwordlist$mean_degree <- as.numeric(CAMwordlist$mean_degree)

### load functions
# print(getwd())
setwd("../../../functions")
for(i in 1:length(dir())){
  # print(dir()[i])
  source(dir()[i], encoding = "utf-8")
}


setwd("../functions_CAMapp")
for(i in 1:length(dir())){
  # print(dir()[i])
  source(dir()[i], encoding = "utf-8")
}
rm(i)



### summary function
data_summary <- function(data, varname, groupnames){
  require(plyr)
  summary_func <- function(x, col){
    c(mean = mean(x[[col]], na.rm=TRUE),
      se = sd(x[[col]], na.rm=TRUE) / sqrt(length(x[[col]])))
  }
  data_sum<-ddply(data, groupnames, .fun=summary_func,
                  varname)
  data_sum <- plyr::rename(data_sum, c("mean" = varname))
  return(data_sum)
}
```

# Open text answers


## Material system that has been thought of

Question:  Bitte beschreiben Sie an an welches Materialsystem oder welche Materialsysteme Sie dabei gedacht haben. 

```{r}
#| label: material thought of

DT::datatable(questionnaire[,c("PROLIFIC_PID", "openQuestion_MaterialSystem")], options = list(pageLength = 5)) 
```

## basal attributes: most pos. / neg.

Question: Welche drei Begriffen nehmen Sie am positivsten bzw. negativsten für die Beschreibung neuer Materialsysteme wahr?


```{r}
#| label: most pos, most neg

## most positive
tmp <- str_trim(unlist(str_split(string = questionnaire$multiplePositive, pattern = "\\\\")))
sort(table(tmp))

## most negative
tmp <- str_trim(unlist(str_split(string = questionnaire$multipleNegative, pattern = "\\\\")))
sort(table(tmp))

## answers of participants
DT::datatable(questionnaire[,c("PROLIFIC_PID", "multiplePositive", "multipleNegative")], options = list(pageLength = 5)) 
```


**any basal attributes missing?**

Question:  Fallen Ihnen weitere Eigenschaften ein, die Sie als relevant oder negativ für die Beschreibung neuer Materialsysteme erachten, die in der Liste nicht aufgeführt sind, so können Sie diese gerne in folgenden Textfeldern ergänzen: 


```{r}
#| label: basal attribute missing


tmp_dat <- questionnaire[,c("PROLIFIC_PID", "openQuestion_missedPositive", "openQuestion_missedNegative")]
tmp_dat <- tmp_dat[!is.na(tmp_dat$openQuestion_missedPositive) | !is.na(tmp_dat$openQuestion_missedNegative), ]

## answers of participants
DT::datatable(tmp_dat, options = list(pageLength = 5)) 
```



## basal attributes: ethical most relevant

Question:  Welche drei Begriffe sind aus Ihrer Sicht in moralischer Hinsicht am "relevantesten"?


```{r}
#| label: ethical relevant

## ethical relevant
tmp <- str_trim(unlist(str_split(string = questionnaire$multipleEthic, pattern = "\\\\")))
sort(table(tmp))

## answers of participants
DT::datatable(questionnaire[,c("PROLIFIC_PID", "multipleEthic")], options = list(pageLength = 5)) 
```

**argument for choosen basal attributes**

Question: Bitte begründen Sie kurz die Auswahl der ethisch relevanten Begriffe:


```{r}
#| label: argument ethical relevant

## answers of participants
DT::datatable(questionnaire[,c("PROLIFIC_PID", "multipleEthic", "openQuestion_Ethic")], options = list(pageLength = 5)) 
```


## outcome questions

Question: Sollte die Entwicklung innovativer Materialsysteme mit öffentlichen Mitteln gefördert werden? 	

```{r}
#| label: outcome research

table(questionnaire$outcome_research)
```

Question: Sollten die Erforschung und Entwicklung solcher innovativer Materialsysteme verboten werden?

```{r}
#| label: outcome prohibition

table(questionnaire$outcome_prohibition)
```

Question: Wären Sie bereit, Produkte zu kaufen, die innovative Materialsysteme enthalten? 


```{r}
#| label: outcome buy

table(questionnaire$outcome_buy)
```

> if yes to previous question

Question: An welche möglichen Produkte haben Sie gedacht? 

```{r}
#| label: outcome buy - text
#| 
## answers of participants
tmp_dat <- questionnaire[,c("PROLIFIC_PID", "outcome_buy_text")]
tmp_dat <- tmp_dat[!is.na(tmp_dat$outcome_buy_text),] 
DT::datatable(tmp_dat, options = list(pageLength = 5)) 
```

## feedback to the study

Question: 

```{r}
#| label: feedback critic

DT::datatable(questionnaire[!is.na(questionnaire$feedback_critic),c("PROLIFIC_PID", "feedback_critic")], options = list(pageLength = 5)) 
```


# analyses (natural language processing)

## sentiment analysis


! remove no results

```{r}
#| label: save data for sentiment analysis

setwd("03_partII_text_sentiment analysis")


tmp_dat <-  questionnaire[, c("PROLIFIC_PID", "multipleEthic", "openQuestion_Ethic")]

write.xlsx2(x = tmp_dat, file = "data_text.xlsx", fileEncoding = "UTF-8", row.names = FALSE)

tmp_dat <-  read.xlsx2(file = "data_text_translated.xlsx", sheetIndex = 1)
write.csv(x = tmp_dat, file = "data_text.csv")
```

```{r}
#| label: predicting significant mean differences in CAMs

setwd("03_partII_text_sentiment analysis")

sentimentAnalysis <- read.csv(file = "sentiment_text.csv", header = TRUE)
table(sentimentAnalysis$sentimentVadder)

networkIndicators$sentimentVadder <- sentimentAnalysis$sentimentVadder
networkIndicators$sentimentVadder <- as.factor(networkIndicators$sentimentVadder)
boxplot(networkIndicators$mean_valence_macro ~ networkIndicators$sentimentVadder)
```




## Latent Dirichlet Allocation

a statistical model used primarily for topic modeling, which allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar

```{r}
#| warnings: false


articles_corpus_tdm <- tm::TermDocumentMatrix(questionnaire$openQuestion_Ethic[nchar(questionnaire$openQuestion_Ethic) >= 100],
                                   control =
                                     list(removePunctuation = TRUE,
                                          stopwords = stopwords::stopwords("de"),
                                          tolower = TRUE,
                                          stemming = FALSE,
                                          removeNumbers = TRUE,
                                          bounds = list(global = c(2, Inf)),
                                          wordLengths = c(3, 30))) # sensitive to keep only words with at least 3 characters
inspect(articles_corpus_tdm[1:10,])


DTM <- as.DocumentTermMatrix(x = articles_corpus_tdm)

result_LDAtuning <- ldatuning::FindTopicsNumber(
  DTM,
  topics = seq(from = 2, to = 20, by = 1),
  metrics = c("CaoJuan2009",  "Deveaud2014"),
  method = "Gibbs",
  control = list(seed = 77),
  verbose = TRUE
)

ldatuning::FindTopicsNumber_plot(result_LDAtuning)



# number of topics
K <- 6
# set random number generator seed
set.seed(111)
# compute the LDA model, inference via 1000 iterations of Gibbs sampling
topicModel <- topicmodels::LDA(x = DTM, k = K, method="Gibbs", control=list(iter = 500, verbose = 25))

terms(topicModel, 10)



for(i in 1:K){
  topic <- i
  df <- data.frame(term = topicModel@terms, p = exp(topicModel@beta[topic,]))
  head(df[order(-df$p),])
  
  mycolors <- RColorBrewer::brewer.pal(8, "Dark2")
  wordcloud::wordcloud(df$term, df$p, random.order = FALSE, color = mycolors, max.words = 300)
}

```


# identify persons who talked about environment, nature

```{r}
tmp_dat <- questionnaire[, c("PROLIFIC_PID", "multipleEthic", "openQuestion_Ethic")]


### sort multipleEthic

for(i in 1:nrow(tmp_dat)){
  tmp <- unlist(str_split(string = tmp_dat$multipleEthic[i], pattern = "\\\\"))
  tmp <- str_trim(string = tmp, side = "both")
  tmp <- sort(tmp)
  
  tmp_dat$multipleEthic[i] <- paste0(tmp, collapse = " \\ ")
}


sort(table(tmp_dat$multipleEthic))


### get Boolean value is something related to nature / environment was mentioned
tmp_dat$boolean_ecology <- str_detect(string = tmp_dat$openQuestion_Ethic, pattern = "Umwelt|Nachhaltigkeit|nachhaltig|ökologisch|Klima|Ökosystem|umweltfreundlich|Natur")

table(tmp_dat$boolean_ecology) / nrow(tmp_dat)

tmp_dat$openQuestion_Ethic[tmp_dat$boolean_ecology == FALSE]





setwd("outputs/03_partII_text")
xlsx::write.xlsx2(x = tmp_dat, file = "ethicalRelevance.xlsx")
```

